"""
Gradio WebUI for Agentic RAG System
æä¾›çŸ¥è¯†åº“ç®¡ç†ã€æ–‡æ¡£ä¸Šä¼ ã€è¯„æµ‹é›†ä¸Šä¼ å’Œé—®ç­”åŠŸèƒ½çš„Webç•Œé¢
"""

import asyncio
import gradio as gr
import pandas as pd
import os
import json
import shutil
import time
from datetime import datetime
from pathlib import Path
from typing import Optional, List, Dict, Tuple
from dotenv import load_dotenv
from concurrent.futures import ThreadPoolExecutor, as_completed
from threading import Lock

from document_loader import load_and_chunk_docx
from rag_agent import AgenticRAG, get_kimi_client, rewrite_query, evaluate_answer
from batch_evaluation import evaluate_with_standard
from agno.agent import Agent

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()


def parse_evaluation_json(content: str) -> dict:
    """
    è§£æè¯„æµ‹ç»“æœ JSON
    
    Args:
        content: LLM ç”Ÿæˆçš„ JSON å­—ç¬¦ä¸²
        
    Returns:
        åŒ…å« score å’Œ reasoning çš„å­—å…¸
    """
    import re
    try:
        # å°è¯•ç›´æ¥è§£æ
        result = json.loads(content)
        return result
    except json.JSONDecodeError:
        # å°è¯•æå– JSON éƒ¨åˆ†
        try:
            # æŸ¥æ‰¾ JSON å¯¹è±¡
            json_match = re.search(r'\{[^{}]*"score"[^{}]*"reasoning"[^{}]*\}', content, re.DOTALL)
            if json_match:
                return json.loads(json_match.group())
            
            # å°è¯•å¦ä¸€ç§æ¨¡å¼
            json_match = re.search(r'\{.*?\}', content, re.DOTALL)
            if json_match:
                return json.loads(json_match.group())
        except:
            pass
        
        return {"score": 0.0, "reasoning": "è¯„æµ‹å¤±è´¥ï¼šæ— æ³•è§£æ JSON å“åº”"}


def stream_evaluate_with_standard(
    client,
    query: str,
    generated_answer: str,
    standard_answer: str,
    context: str
):
    """
    æµå¼è¯„æµ‹ç”Ÿæˆç­”æ¡ˆä¸æ ‡å‡†ç­”æ¡ˆçš„åŒ¹é…åº¦
    
    Yields:
        è¯„æµ‹å†…å®¹çš„æµå¼æ›´æ–°
    """
    system_prompt = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ RAG ç³»ç»Ÿè¯„æµ‹å‘˜ã€‚ä½ çš„ä»»åŠ¡æ˜¯è¯„ä¼° [RAGç”Ÿæˆç­”æ¡ˆ] ç›¸å¯¹äº [æ ‡å‡†ç­”æ¡ˆ] çš„è´¨é‡ã€‚

è¯„æµ‹ç»´åº¦ï¼š
1. **å‡†ç¡®æ€§ (Accuracy)**: [RAGç”Ÿæˆç­”æ¡ˆ] æ˜¯å¦æ­£ç¡®å›ç­”äº† [ç”¨æˆ·é—®é¢˜]ï¼Œä¸ [æ ‡å‡†ç­”æ¡ˆ] çš„ä¸€è‡´æ€§å¦‚ä½•ã€‚
2. **å¿ å®åº¦ (Faithfulness)**: [RAGç”Ÿæˆç­”æ¡ˆ] æ˜¯å¦åŸºäº [ä¸Šä¸‹æ–‡]ï¼Œæ²¡æœ‰æé€ ä¿¡æ¯ã€‚
3. **å®Œæ•´æ€§ (Completeness)**: [RAGç”Ÿæˆç­”æ¡ˆ] æ˜¯å¦åŒ…å«äº† [æ ‡å‡†ç­”æ¡ˆ] ä¸­çš„å…³é”®ä¿¡æ¯ã€‚

è¯„åˆ†æ ‡å‡†ï¼š
- 1.0: ä¸æ ‡å‡†ç­”æ¡ˆå®Œå…¨ä¸€è‡´æˆ–æ›´å¥½ï¼Œå‡†ç¡®ä¸”å®Œæ•´
- 0.8-0.9: ä¸æ ‡å‡†ç­”æ¡ˆåŸºæœ¬ä¸€è‡´ï¼Œæœ‰è½»å¾®å·®å¼‚ä½†ä¸å½±å“å‡†ç¡®æ€§
- 0.6-0.7: åŒ…å«æ ‡å‡†ç­”æ¡ˆçš„ä¸»è¦å†…å®¹ï¼Œä½†æœ‰æ˜æ˜¾é—æ¼æˆ–ä¸å¤Ÿå‡†ç¡®
- 0.4-0.5: éƒ¨åˆ†æ­£ç¡®ï¼Œä½†æœ‰é‡è¦ä¿¡æ¯ç¼ºå¤±æˆ–åå·®
- 0.0-0.3: ä¸æ ‡å‡†ç­”æ¡ˆä¸¥é‡ä¸ç¬¦ï¼Œé”™è¯¯æˆ–ä¸¥é‡ä¸å®Œæ•´

**é‡è¦**ï¼šä½ å¿…é¡»è¿”å›ä¸€ä¸ª JSON å¯¹è±¡ï¼ŒåŒ…å«ä»¥ä¸‹å­—æ®µï¼š
- "score": æµ®ç‚¹æ•°ï¼ŒèŒƒå›´ 0.0 åˆ° 1.0
- "reasoning": å­—ç¬¦ä¸²ï¼Œè¯¦ç»†è§£é‡Šè¯„åˆ†ç†ç”±

åªè¿”å› JSON å¯¹è±¡ï¼Œä¸è¦åŒ…å«å…¶ä»–å†…å®¹ã€‚"""

    user_prompt = f"""è¯·è¯„æµ‹ä»¥ä¸‹ç­”æ¡ˆï¼š

[ç”¨æˆ·é—®é¢˜]
{query}

[æ ‡å‡†ç­”æ¡ˆ]
{standard_answer}

[RAGç”Ÿæˆç­”æ¡ˆ]
{generated_answer}

[ä¸Šä¸‹æ–‡]
{context}

è¯·æ ¹æ®å‡†ç¡®æ€§ã€å¿ å®åº¦å’Œå®Œæ•´æ€§è¿›è¡Œè¯„åˆ†ï¼Œå¹¶è¿”å› JSON æ ¼å¼çš„è¯„æµ‹ç»“æœã€‚"""

    agent = Agent(
        model=client,
        markdown=False
    )
    
    combined_prompt = f"""{system_prompt}

---

{user_prompt}"""
    
    # æµå¼ç”Ÿæˆè¯„æµ‹ç»“æœ
    eval_content = ""
    for chunk in agent.run(combined_prompt, stream=True):
        if hasattr(chunk, 'content'):
            content = chunk.content
        else:
            content = str(chunk)
        
        if content:
            eval_content += content
            yield eval_content


def stream_evaluate_answer(
    client,
    query: str,
    generated_answer: str,
    context: str
):
    """
    æµå¼è¯„æµ‹ç”Ÿæˆç­”æ¡ˆçš„è´¨é‡ï¼ˆæ— æ ‡å‡†ç­”æ¡ˆï¼ŒåŸºäºä¸Šä¸‹æ–‡è‡ªè¯„ï¼‰
    
    Yields:
        è¯„æµ‹å†…å®¹çš„æµå¼æ›´æ–°
    """
    system_prompt = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ RAG ç³»ç»Ÿè¯„æµ‹å‘˜ã€‚ä½ çš„ä»»åŠ¡æ˜¯è¯„ä¼° [ç”Ÿæˆç­”æ¡ˆ] çš„è´¨é‡ã€‚

è¯„æµ‹ç»´åº¦ï¼š
1. **å‡†ç¡®æ€§ (Accuracy)**: åˆ¤æ–­ [ç”Ÿæˆç­”æ¡ˆ] æ˜¯å¦æ­£ç¡®å›ç­”äº† [ç”¨æˆ·é—®é¢˜]ã€‚
2. **å¿ å®åº¦ (Faithfulness)**: åˆ¤æ–­ [ç”Ÿæˆç­”æ¡ˆ] ä¸­çš„ä¿¡æ¯æ˜¯å¦**å®Œå…¨**åŸºäº [ä¸Šä¸‹æ–‡]ï¼Œæ²¡æœ‰æé€ æˆ–æ·»åŠ ä¸Šä¸‹æ–‡ä¸­ä¸å­˜åœ¨çš„ä¿¡æ¯ã€‚
3. **å®Œæ•´æ€§ (Completeness)**: åˆ¤æ–­ [ç”Ÿæˆç­”æ¡ˆ] æ˜¯å¦å……åˆ†åˆ©ç”¨äº† [ä¸Šä¸‹æ–‡] ä¸­çš„ç›¸å…³ä¿¡æ¯ã€‚

è¯„åˆ†æ ‡å‡†ï¼š
- 1.0: å®Œå…¨å‡†ç¡®ã€å®Œå…¨å¿ å®ã€ä¿¡æ¯å®Œæ•´
- 0.7-0.9: åŸºæœ¬å‡†ç¡®ä¸”å¿ å®ï¼Œä½†å¯èƒ½æœ‰è½»å¾®ä¸å®Œæ•´
- 0.4-0.6: éƒ¨åˆ†æ­£ç¡®ä½†æœ‰æ˜æ˜¾é—æ¼æˆ–è½»å¾®åå·®
- 0.0-0.3: é”™è¯¯ç­”æ¡ˆã€ä¸¥é‡æé€ æˆ–ä¸¥é‡åç¦»ä¸Šä¸‹æ–‡

**é‡è¦**ï¼šä½ å¿…é¡»è¿”å›ä¸€ä¸ª JSON å¯¹è±¡ï¼ŒåŒ…å«ä»¥ä¸‹å­—æ®µï¼š
- "score": æµ®ç‚¹æ•°ï¼ŒèŒƒå›´ 0.0 åˆ° 1.0
- "reasoning": å­—ç¬¦ä¸²ï¼Œè¯¦ç»†è§£é‡Šè¯„åˆ†ç†ç”±

åªè¿”å› JSON å¯¹è±¡ï¼Œä¸è¦åŒ…å«å…¶ä»–å†…å®¹ã€‚"""

    user_prompt = f"""è¯·è¯„æµ‹ä»¥ä¸‹ç­”æ¡ˆï¼š

[ç”¨æˆ·é—®é¢˜]
{query}

[ä¸Šä¸‹æ–‡]
{context}

[ç”Ÿæˆç­”æ¡ˆ]
{generated_answer}

è¯·æ ¹æ®å‡†ç¡®æ€§ã€å¿ å®åº¦å’Œå®Œæ•´æ€§è¿›è¡Œè¯„åˆ†ï¼Œå¹¶è¿”å› JSON æ ¼å¼çš„è¯„æµ‹ç»“æœã€‚"""

    agent = Agent(
        model=client,
        markdown=False
    )
    
    combined_prompt = f"""{system_prompt}

---

{user_prompt}"""
    
    # æµå¼ç”Ÿæˆè¯„æµ‹ç»“æœ
    eval_content = ""
    for chunk in agent.run(combined_prompt, stream=True):
        if hasattr(chunk, 'content'):
            content = chunk.content
        else:
            content = str(chunk)
        
        if content:
            eval_content += content
            yield eval_content

# å…¨å±€å˜é‡
KNOWLEDGE_BASE_DIR = Path("knowledge_bases")
EVAL_SETS_DIR = Path("eval_sets")
KNOWLEDGE_BASE_DIR.mkdir(exist_ok=True)
EVAL_SETS_DIR.mkdir(exist_ok=True)

# å…¨å±€ RAG å®ä¾‹ç¼“å­˜ï¼ˆæ ‡è®°çŸ¥è¯†åº“æ˜¯å¦å·²åŠ è½½ï¼‰
rag_instances: Dict[str, bool] = {}
kimi_client = None

# å…¨å±€å…±äº«çš„æ£€ç´¢å™¨ï¼ˆé¢„åŠ è½½æ¨¡å‹ï¼‰
shared_retriever = None

# å…¨å±€çº¿ç¨‹æ± ï¼ˆç”¨äºå¹¶è¡Œæ£€ç´¢ï¼‰
thread_pool = None
chunks_lock = Lock()


def init_shared_retriever():
    """åˆå§‹åŒ–å…±äº«çš„ HybridRetrieverï¼ˆé¢„åŠ è½½æ¨¡å‹ï¼‰"""
    global shared_retriever
    if shared_retriever is None:
        from retriever_hybrid import HybridRetriever
        print("æ­£åœ¨é¢„åŠ è½½æ£€ç´¢æ¨¡å‹ï¼ˆè¿™å¯èƒ½éœ€è¦1-2åˆ†é’Ÿï¼‰...")
        shared_retriever = HybridRetriever()
        print("âœ… æ£€ç´¢æ¨¡å‹é¢„åŠ è½½å®Œæˆï¼")
    return shared_retriever


def init_thread_pool(max_workers: int = 4):
    """åˆå§‹åŒ–çº¿ç¨‹æ± """
    global thread_pool
    if thread_pool is None:
        thread_pool = ThreadPoolExecutor(max_workers=max_workers)
    return thread_pool


def _search_single_query(retriever, args: tuple) -> list:
    """å•ä¸ªæŸ¥è¯¢çš„æ£€ç´¢ï¼ˆç”¨äºå¤šçº¿ç¨‹æ‰§è¡Œï¼‰"""
    query_index, query = args
    return retriever.search(query, top_k=10)


def parallel_search(retriever, rewritten_queries: list) -> dict:
    """å¹¶è¡Œæ‰§è¡Œå¤šä¸ªæŸ¥è¯¢çš„æ£€ç´¢"""
    global thread_pool, chunks_lock
    all_candidate_chunks = {}
    
    pool = init_thread_pool()
    tasks = [(i + 1, query) for i, query in enumerate(rewritten_queries)]
    
    futures = []
    for task in tasks:
        future = pool.submit(_search_single_query, retriever, task)
        futures.append(future)
    
    for future in as_completed(futures):
        try:
            results = future.result()
            for chunk in results:
                para_id = chunk['metadata']['paragraph_id']
                with chunks_lock:
                    all_candidate_chunks[para_id] = chunk
        except Exception as e:
            print(f"æ£€ç´¢ä»»åŠ¡å‡ºé”™: {e}")
    
    return all_candidate_chunks


def init_kimi_client():
    """åˆå§‹åŒ– Kimi å®¢æˆ·ç«¯"""
    global kimi_client
    if kimi_client is None:
        kimi_client = get_kimi_client()
    return kimi_client


def get_knowledge_bases() -> List[str]:
    """è·å–æ‰€æœ‰çŸ¥è¯†åº“åç§°"""
    if not KNOWLEDGE_BASE_DIR.exists():
        return []
    return [d.name for d in KNOWLEDGE_BASE_DIR.iterdir() if d.is_dir()]


def get_eval_sets() -> List[str]:
    """è·å–æ‰€æœ‰è¯„æµ‹é›†åç§°"""
    if not EVAL_SETS_DIR.exists():
        return []
    return [f.stem for f in EVAL_SETS_DIR.glob("*.xlsx")]


def create_knowledge_base(name: str) -> str:
    """åˆ›å»ºæ–°çš„çŸ¥è¯†åº“"""
    if not name or not name.strip():
        return "âŒ é”™è¯¯ï¼šçŸ¥è¯†åº“åç§°ä¸èƒ½ä¸ºç©º"
    
    name = name.strip()
    kb_path = KNOWLEDGE_BASE_DIR / name
    
    if kb_path.exists():
        return f"âŒ é”™è¯¯ï¼šçŸ¥è¯†åº“ '{name}' å·²å­˜åœ¨"
    
    try:
        kb_path.mkdir(parents=True)
        (kb_path / "documents").mkdir()
        (kb_path / "index").mkdir()
        
        # åˆ›å»ºå…ƒæ•°æ®æ–‡ä»¶
        metadata = {
            "name": name,
            "created_at": datetime.now().isoformat(),
            "document_count": 0,
            "indexed": False
        }
        with open(kb_path / "metadata.json", "w", encoding="utf-8") as f:
            json.dump(metadata, f, ensure_ascii=False, indent=2)
        
        return f"âœ… æˆåŠŸåˆ›å»ºçŸ¥è¯†åº“ '{name}'"
    except Exception as e:
        return f"âŒ åˆ›å»ºçŸ¥è¯†åº“å¤±è´¥ï¼š{str(e)}"


def delete_knowledge_base(name: str) -> str:
    """åˆ é™¤çŸ¥è¯†åº“"""
    if not name:
        return "âŒ é”™è¯¯ï¼šè¯·é€‰æ‹©è¦åˆ é™¤çš„çŸ¥è¯†åº“"
    
    kb_path = KNOWLEDGE_BASE_DIR / name
    
    if not kb_path.exists():
        return f"âŒ é”™è¯¯ï¼šçŸ¥è¯†åº“ '{name}' ä¸å­˜åœ¨"
    
    try:
        # æ¸…ç†ç¼“å­˜æ ‡è®°
        if name in rag_instances:
            del rag_instances[name]
        
        shutil.rmtree(kb_path)
        return f"âœ… æˆåŠŸåˆ é™¤çŸ¥è¯†åº“ '{name}'"
    except Exception as e:
        return f"âŒ åˆ é™¤çŸ¥è¯†åº“å¤±è´¥ï¼š{str(e)}"


def upload_document(kb_name: str, files: List) -> str:
    """ä¸Šä¼ æ–‡æ¡£åˆ°çŸ¥è¯†åº“"""
    if not kb_name:
        return "âŒ é”™è¯¯ï¼šè¯·å…ˆé€‰æ‹©çŸ¥è¯†åº“"
    
    if not files:
        return "âŒ é”™è¯¯ï¼šè¯·é€‰æ‹©è¦ä¸Šä¼ çš„æ–‡æ¡£"
    
    kb_path = KNOWLEDGE_BASE_DIR / kb_name
    if not kb_path.exists():
        return f"âŒ é”™è¯¯ï¼šçŸ¥è¯†åº“ '{kb_name}' ä¸å­˜åœ¨"
    
    doc_dir = kb_path / "documents"
    uploaded_count = 0
    
    try:
        for file in files:
            if not file.name.endswith(('.docx', '.doc')):
                continue
            
            # å¤åˆ¶æ–‡ä»¶åˆ°çŸ¥è¯†åº“æ–‡æ¡£ç›®å½•
            file_name = Path(file.name).name
            dest_path = doc_dir / file_name
            shutil.copy(file.name, dest_path)
            uploaded_count += 1
        
        # æ›´æ–°å…ƒæ•°æ®
        metadata_path = kb_path / "metadata.json"
        with open(metadata_path, "r", encoding="utf-8") as f:
            metadata = json.load(f)
        
        metadata["document_count"] = len(list(doc_dir.glob("*.docx"))) + len(list(doc_dir.glob("*.doc")))
        metadata["indexed"] = False
        metadata["last_upload"] = datetime.now().isoformat()
        
        with open(metadata_path, "w", encoding="utf-8") as f:
            json.dump(metadata, f, ensure_ascii=False, indent=2)
        
        return f"âœ… æˆåŠŸä¸Šä¼  {uploaded_count} ä¸ªæ–‡æ¡£åˆ°çŸ¥è¯†åº“ '{kb_name}'"
    except Exception as e:
        return f"âŒ ä¸Šä¼ æ–‡æ¡£å¤±è´¥ï¼š{str(e)}"


def build_knowledge_base(kb_name: str, progress=gr.Progress()) -> str:
    """æ„å»ºçŸ¥è¯†åº“ç´¢å¼•"""
    if not kb_name:
        return "âŒ é”™è¯¯ï¼šè¯·å…ˆé€‰æ‹©çŸ¥è¯†åº“"
    
    kb_path = KNOWLEDGE_BASE_DIR / kb_name
    if not kb_path.exists():
        return f"âŒ é”™è¯¯ï¼šçŸ¥è¯†åº“ '{kb_name}' ä¸å­˜åœ¨"
    
    doc_dir = kb_path / "documents"
    index_dir = kb_path / "index"
    
    try:
        progress(0, desc="æ­£åœ¨åŠ è½½æ–‡æ¡£...")
        
        # åŠ è½½æ‰€æœ‰æ–‡æ¡£
        all_chunks = []
        doc_files = list(doc_dir.glob("*.docx")) + list(doc_dir.glob("*.doc"))
        
        if not doc_files:
            return f"âŒ é”™è¯¯ï¼šçŸ¥è¯†åº“ '{kb_name}' ä¸­æ²¡æœ‰æ–‡æ¡£"
        
        for i, doc_file in enumerate(doc_files):
            progress((i + 1) / len(doc_files), desc=f"æ­£åœ¨å¤„ç†æ–‡æ¡£ {i+1}/{len(doc_files)}")
            chunks = load_and_chunk_docx(str(doc_file))
            all_chunks.extend(chunks)
        
        progress(0.8, desc="æ­£åœ¨æ„å»ºç´¢å¼•...")
        
        # ä½¿ç”¨å…±äº«çš„æ£€ç´¢å™¨ï¼ˆå·²é¢„åŠ è½½æ¨¡å‹ï¼‰
        retriever = init_shared_retriever()
        
        # æ¸…ç©ºç°æœ‰ç´¢å¼•
        retriever.clear()
        
        # æ·»åŠ æ–‡æ¡£å—åˆ°æ£€ç´¢å™¨
        for chunk in all_chunks:
            retriever.add_document(chunk['text'], chunk['metadata'])
        
        # ä¿å­˜ç´¢å¼•åˆ°çŸ¥è¯†åº“ç›®å½•
        retriever.save_index(str(index_dir))
        
        # æ›´æ–°å…ƒæ•°æ®
        metadata_path = kb_path / "metadata.json"
        with open(metadata_path, "r", encoding="utf-8") as f:
            metadata = json.load(f)
        
        metadata["indexed"] = True
        metadata["chunk_count"] = len(all_chunks)
        metadata["last_indexed"] = datetime.now().isoformat()
        
        with open(metadata_path, "w", encoding="utf-8") as f:
            json.dump(metadata, f, ensure_ascii=False, indent=2)
        
        # æ ‡è®°è¯¥çŸ¥è¯†åº“å·²åŠ è½½ï¼ˆç´¢å¼•å·²åœ¨å…±äº«æ£€ç´¢å™¨ä¸­ï¼‰
        rag_instances[kb_name] = True
        
        progress(1.0, desc="å®Œæˆ")
        
        return f"âœ… æˆåŠŸæ„å»ºçŸ¥è¯†åº“ '{kb_name}'\nå¤„ç†æ–‡æ¡£æ•°: {len(doc_files)}\næ–‡æ¡£å—æ•°: {len(all_chunks)}"
    except Exception as e:
        return f"âŒ æ„å»ºçŸ¥è¯†åº“å¤±è´¥ï¼š{str(e)}"


def upload_eval_set(file) -> str:
    """ä¸Šä¼ è¯„æµ‹é›†"""
    if not file:
        return "âŒ é”™è¯¯ï¼šè¯·é€‰æ‹©è¦ä¸Šä¼ çš„è¯„æµ‹é›†æ–‡ä»¶"
    
    if not file.name.endswith('.xlsx'):
        return "âŒ é”™è¯¯ï¼šè¯„æµ‹é›†æ–‡ä»¶å¿…é¡»æ˜¯ .xlsx æ ¼å¼"
    
    try:
        # éªŒè¯æ–‡ä»¶æ ¼å¼
        df = pd.read_excel(file.name)
        if 'query' not in df.columns or 'standard_answer' not in df.columns:
            return "âŒ é”™è¯¯ï¼šè¯„æµ‹é›†å¿…é¡»åŒ…å« 'query' å’Œ 'standard_answer' åˆ—"
        
        # ä¿å­˜æ–‡ä»¶
        file_name = Path(file.name).name
        dest_path = EVAL_SETS_DIR / file_name
        shutil.copy(file.name, dest_path)
        
        return f"âœ… æˆåŠŸä¸Šä¼ è¯„æµ‹é›† '{file_name}'\nåŒ…å« {len(df)} æ¡è¯„æµ‹æ•°æ®"
    except Exception as e:
        return f"âŒ ä¸Šä¼ è¯„æµ‹é›†å¤±è´¥ï¼š{str(e)}"


def load_knowledge_base_index(kb_name: str) -> bool:
    """
    åŠ è½½çŸ¥è¯†åº“ç´¢å¼•åˆ°å…±äº«æ£€ç´¢å™¨
    
    Returns:
        æ˜¯å¦æˆåŠŸåŠ è½½
    """
    if not kb_name:
        return False
    
    # å¦‚æœå·²åŠ è½½ï¼Œç›´æ¥è¿”å›
    if kb_name in rag_instances:
        return True
    
    kb_path = KNOWLEDGE_BASE_DIR / kb_name
    if not kb_path.exists():
        return False
    
    index_dir = kb_path / "index"
    if not index_dir.exists():
        return False
    
    # æ£€æŸ¥ç´¢å¼•æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    bm25_path = index_dir / "bm25" / "chunks.pkl"
    vector_path = index_dir / "vector" / "faiss.index"
    if not bm25_path.exists() or not vector_path.exists():
        return False
    
    try:
        # ä½¿ç”¨å…±äº«æ£€ç´¢å™¨åŠ è½½ç´¢å¼•
        retriever = init_shared_retriever()
        retriever.load_index(str(index_dir))
        
        # æ ‡è®°å·²åŠ è½½
        rag_instances[kb_name] = True
        return True
    except Exception as e:
        print(f"åŠ è½½çŸ¥è¯†åº“ç´¢å¼•å¤±è´¥ï¼š{str(e)}")
        return False


def answer_question_sync(
    kb_name: str,
    eval_set_name: str,
    question: str,
    enable_eval: bool
):
    """
    å›ç­”é—®é¢˜å¹¶è¯„æµ‹ï¼ˆæµå¼è¾“å‡ºï¼ŒåŒæ­¥ç”Ÿæˆå™¨ï¼‰
    
    Yields:
        (answer, context, evaluation_result, time_stats) çš„æµå¼æ›´æ–°
    """
    if not kb_name:
        yield "âŒ è¯·å…ˆé€‰æ‹©çŸ¥è¯†åº“", "", "", ""
        return
    
    if not question or not question.strip():
        yield "âŒ è¯·è¾“å…¥é—®é¢˜", "", "", ""
        return
    
    # åŠ è½½çŸ¥è¯†åº“ç´¢å¼•
    if not load_knowledge_base_index(kb_name):
        yield f"âŒ æ— æ³•åŠ è½½çŸ¥è¯†åº“ '{kb_name}'ï¼Œè¯·å…ˆæ„å»ºç´¢å¼•", "", "", ""
        return
    
    # è·å–å…±äº«æ£€ç´¢å™¨
    retriever = init_shared_retriever()
    
    # åˆå§‹åŒ– Kimi å®¢æˆ·ç«¯
    client = init_kimi_client()
    
    # å¼€å§‹è®¡æ—¶
    start_time = time.time()
    
    try:
        # åˆå§‹çŠ¶æ€
        yield "â³ æ­£åœ¨é‡å†™æŸ¥è¯¢...", "", "", "â³ è®¡æ—¶ä¸­..."
        
        # 1. æŸ¥è¯¢é‡å†™ï¼ˆåœ¨äº‹ä»¶å¾ªç¯ä¸­è¿è¡Œå¼‚æ­¥å‡½æ•°ï¼‰
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        try:
            rewritten_queries = loop.run_until_complete(rewrite_query(client, question))
        finally:
            loop.close()
        
        yield "â³ æ­£åœ¨æ£€ç´¢æ–‡æ¡£ï¼ˆå¤šçº¿ç¨‹å¹¶è¡Œï¼‰...", "", "", "â³ è®¡æ—¶ä¸­..."
        
        # 2. æ··åˆæ£€ç´¢ï¼ˆå¤šçº¿ç¨‹å¹¶è¡Œï¼‰
        all_candidate_chunks = parallel_search(retriever, rewritten_queries)
        final_candidates = list(all_candidate_chunks.values())
        
        yield "â³ æ­£åœ¨é‡æ’åº...", "", "", "â³ è®¡æ—¶ä¸­..."
        
        # 3. æœ€ç»ˆé‡æ’
        pairs = [(question, chunk['text']) for chunk in final_candidates]
        scores = retriever.reranker.compute_score(pairs, batch_size=4)
        
        # Handle case where scores might be None
        if scores is None:
            scores = [0.0] * len(final_candidates)
        
        scored_chunks = list(zip(scores, final_candidates))
        scored_chunks.sort(key=lambda x: x[0], reverse=True)
        top_k_chunks = [chunk for score, chunk in scored_chunks[:3]]
        
        # æ„å»ºä¸Šä¸‹æ–‡
        context_str = ""
        for idx, chunk in enumerate(top_k_chunks, 1):
            context_str += f"[æ–‡æ¡£ç‰‡æ®µ {idx}]\n{chunk['text']}\n\n"
        
        # æµå¼æ˜¾ç¤ºä¸Šä¸‹æ–‡
        yield "â³ æ­£åœ¨ç”Ÿæˆç­”æ¡ˆ...", context_str, "", "â³ è®¡æ—¶ä¸­..."
        
        # 4. ç”Ÿæˆç­”æ¡ˆï¼ˆæµå¼ï¼‰
        system_prompt = """ä½ æ˜¯ä¸€ä¸ªé—®ç­”åŠ©æ‰‹ã€‚è¯·æ ¹æ®ä¸‹é¢æä¾›çš„ [ä¸Šä¸‹æ–‡]ï¼Œç”¨ä¸­æ–‡å›ç­” [ç”¨æˆ·é—®é¢˜]ã€‚

ä½ çš„å›ç­”å¿…é¡»ä¸¥æ ¼åŸºäº [ä¸Šä¸‹æ–‡] åŒ…å«çš„ä¿¡æ¯ï¼Œç¦æ­¢æé€ ã€‚å¦‚æœä¸Šä¸‹æ–‡ä¸­æ²¡æœ‰è¶³å¤Ÿçš„ä¿¡æ¯ï¼Œè¯·æ˜ç¡®è¯´æ˜ã€‚"""
        
        user_prompt = f"""[ä¸Šä¸‹æ–‡]:
{context_str}

[ç”¨æˆ·é—®é¢˜]:
{question}"""
        
        agent = Agent(
            model=client,
            markdown=False
        )
        
        combined_prompt = f"""{system_prompt}

---

{user_prompt}"""
        
        # æµå¼ç”Ÿæˆç­”æ¡ˆ
        generated_answer = ""
        for chunk in agent.run(combined_prompt, stream=True):
            if hasattr(chunk, 'content'):
                content = chunk.content
            else:
                content = str(chunk)
            
            if content:
                generated_answer += content
                elapsed = time.time() - start_time
                yield generated_answer, context_str, "", f"â³ ç”Ÿæˆä¸­... ({elapsed:.1f}s)"
        
        # 5. è¯„æµ‹ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        eval_result = ""
        
        # è®¡ç®—ç­”æ¡ˆç”Ÿæˆå®Œæˆçš„æ—¶é—´
        answer_time = time.time() - start_time
        
        if enable_eval:
            yield generated_answer, context_str, "â³ æ­£åœ¨è¯„æµ‹ç­”æ¡ˆ...", f"â³ ç­”æ¡ˆç”Ÿæˆè€—æ—¶: {answer_time:.1f}s"
            
            standard_answer = None
            
            # å¦‚æœé€‰æ‹©äº†è¯„æµ‹é›†ï¼Œå°è¯•æŸ¥æ‰¾åŒ¹é…çš„æ ‡å‡†ç­”æ¡ˆ
            if eval_set_name:
                eval_file = EVAL_SETS_DIR / f"{eval_set_name}.xlsx"
                if eval_file.exists():
                    df = pd.read_excel(eval_file)
                    
                    # æ ‡å‡†åŒ–é—®é¢˜æ–‡æœ¬ç”¨äºåŒ¹é…ï¼ˆå»é™¤ç©ºæ ¼ã€æ ‡ç‚¹å·®å¼‚ï¼‰
                    def normalize_text(text):
                        import re
                        if pd.isna(text):
                            return ""
                        text = str(text).strip()
                        # ç§»é™¤æ‰€æœ‰ç©ºç™½å­—ç¬¦
                        text = re.sub(r'\s+', '', text)
                        # ç»Ÿä¸€ä¸­è‹±æ–‡æ ‡ç‚¹
                        text = text.replace('ï¼Ÿ', '?').replace('ã€‚', '.').replace('ï¼Œ', ',')
                        return text.lower()
                    
                    user_question_normalized = normalize_text(question)
                    
                    # æŸ¥æ‰¾åŒ¹é…çš„è¡Œ
                    matching_rows = df[df['query'].apply(normalize_text) == user_question_normalized]
                    
                    # å¦‚æœç²¾ç¡®åŒ¹é…æ‰¾ä¸åˆ°ï¼Œå°è¯•åŒ…å«åŒ¹é…
                    if matching_rows.empty:
                        matching_rows = df[df['query'].apply(lambda x: normalize_text(x) in user_question_normalized or user_question_normalized in normalize_text(x))]
                    
                    if not matching_rows.empty:
                        standard_answer = matching_rows.iloc[0]['standard_answer']
            
            # æ ¹æ®æ˜¯å¦æœ‰æ ‡å‡†ç­”æ¡ˆé€‰æ‹©è¯„æµ‹æ–¹å¼ï¼ˆæµå¼è¾“å‡ºï¼‰
            if standard_answer:
                # æœ‰æ ‡å‡†ç­”æ¡ˆï¼šä½¿ç”¨æ ‡å‡†ç­”æ¡ˆè¿›è¡Œè¯„æµ‹
                eval_header = f"""ğŸ“Š è¯„æµ‹ç»“æœï¼ˆå¯¹æ¯”æ ‡å‡†ç­”æ¡ˆï¼‰:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ“ æ ‡å‡†ç­”æ¡ˆ:
{standard_answer}

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ¤– AI è¯„æµ‹ä¸­...
"""
                yield generated_answer, context_str, eval_header, f"â³ ç­”æ¡ˆç”Ÿæˆè€—æ—¶: {answer_time:.1f}s"
                
                # æµå¼è¯„æµ‹
                eval_content = ""
                for eval_chunk in stream_evaluate_with_standard(
                    client, question, generated_answer, standard_answer, context_str
                ):
                    eval_content = eval_chunk
                    yield generated_answer, context_str, eval_header + eval_content, f"â³ è¯„æµ‹ä¸­..."
                
                # è§£æè¯„æµ‹ç»“æœ
                evaluation = parse_evaluation_json(eval_content)
                eval_result = f"""ğŸ“Š è¯„æµ‹ç»“æœï¼ˆå¯¹æ¯”æ ‡å‡†ç­”æ¡ˆï¼‰:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ“ æ ‡å‡†ç­”æ¡ˆ:
{standard_answer}

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
â­ å¾—åˆ†: {evaluation.get('score', 0.0):.2f} / 1.0

ğŸ’¡ è¯„æµ‹ç†ç”±:
{evaluation.get('reasoning', 'æ— ')}
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"""
            else:
                # æ— æ ‡å‡†ç­”æ¡ˆï¼šä½¿ç”¨åŸºäºä¸Šä¸‹æ–‡çš„è‡ªæˆ‘è¯„æµ‹
                eval_header = """ğŸ“Š è¯„æµ‹ç»“æœï¼ˆåŸºäºä¸Šä¸‹æ–‡è‡ªè¯„ï¼‰:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
â„¹ï¸ è¯„æµ‹æ¨¡å¼: æœªæ‰¾åˆ°æ ‡å‡†ç­”æ¡ˆï¼Œä½¿ç”¨ä¸Šä¸‹æ–‡è‡ªè¯„

ğŸ¤– AI è¯„æµ‹ä¸­...
"""
                yield generated_answer, context_str, eval_header, f"â³ ç­”æ¡ˆç”Ÿæˆè€—æ—¶: {answer_time:.1f}s"
                
                # æµå¼è¯„æµ‹
                eval_content = ""
                for eval_chunk in stream_evaluate_answer(
                    client, question, generated_answer, context_str
                ):
                    eval_content = eval_chunk
                    yield generated_answer, context_str, eval_header + eval_content, f"â³ è¯„æµ‹ä¸­..."
                
                # è§£æè¯„æµ‹ç»“æœ
                evaluation = parse_evaluation_json(eval_content)
                eval_result = f"""ğŸ“Š è¯„æµ‹ç»“æœï¼ˆåŸºäºä¸Šä¸‹æ–‡è‡ªè¯„ï¼‰:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
â„¹ï¸ è¯„æµ‹æ¨¡å¼: æœªæ‰¾åˆ°æ ‡å‡†ç­”æ¡ˆï¼Œä½¿ç”¨ä¸Šä¸‹æ–‡è‡ªè¯„

â­ å¾—åˆ†: {evaluation.get('score', 0.0):.2f} / 1.0

ğŸ’¡ è¯„æµ‹ç†ç”±:
{evaluation.get('reasoning', 'æ— ')}
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"""
        
        # è®¡ç®—æ€»è€—æ—¶
        total_time = time.time() - start_time
        
        # è€—æ—¶ç»Ÿè®¡å•ç‹¬è¾“å‡º
        time_stats = f"â±ï¸ è€—æ—¶ç»Ÿè®¡:\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\nâ€¢ ç­”æ¡ˆç”Ÿæˆ: {answer_time:.1f}s\nâ€¢ æ€»è€—æ—¶: {total_time:.1f}s"
        
        # æœ€ç»ˆç»“æœ
        yield generated_answer, context_str, eval_result, time_stats
        
    except Exception as e:
        import traceback
        traceback.print_exc()
        yield f"âŒ å¤„ç†å¤±è´¥ï¼š{str(e)}", "", "", "âŒ è®¡æ—¶å¤±è´¥"


def refresh_kb_list():
    """åˆ·æ–°çŸ¥è¯†åº“åˆ—è¡¨"""
    choices = get_knowledge_bases()
    return (
        gr.update(choices=choices),
        gr.update(choices=choices),
        gr.update(choices=choices),
        gr.update(choices=choices)
    )


def refresh_eval_list():
    """åˆ·æ–°è¯„æµ‹é›†åˆ—è¡¨"""
    choices = get_eval_sets()
    return (
        gr.update(choices=choices),
        gr.update(choices=choices)
    )


# åˆ›å»º Gradio ç•Œé¢
def create_webui():
    """åˆ›å»º Gradio WebUI"""
    
    with gr.Blocks(title="Agentic RAG System") as app:
        gr.Markdown("""
        # ğŸ¤– Agentic RAG System
        
        æ™ºèƒ½æ£€ç´¢å¢å¼ºç”Ÿæˆç³»ç»Ÿ - çŸ¥è¯†åº“ç®¡ç†ä¸é—®ç­”å¹³å°
        """)
        
        with gr.Tabs():
            # Tab 1: çŸ¥è¯†åº“ç®¡ç†
            with gr.Tab("ğŸ“š çŸ¥è¯†åº“ç®¡ç†"):
                gr.Markdown("### åˆ›å»ºä¸ç®¡ç†çŸ¥è¯†åº“")
                
                with gr.Row():
                    with gr.Column():
                        kb_name_input = gr.Textbox(
                            label="çŸ¥è¯†åº“åç§°",
                            placeholder="è¾“å…¥æ–°çŸ¥è¯†åº“çš„åç§°..."
                        )
                        create_kb_btn = gr.Button("åˆ›å»ºçŸ¥è¯†åº“", variant="primary")
                        create_kb_output = gr.Textbox(label="æ“ä½œç»“æœ", lines=2)
                    
                    with gr.Column():
                        kb_list = gr.Dropdown(
                            label="é€‰æ‹©çŸ¥è¯†åº“",
                            choices=get_knowledge_bases(),
                            interactive=True
                        )
                        refresh_kb_btn = gr.Button("åˆ·æ–°åˆ—è¡¨")
                        delete_kb_btn = gr.Button("åˆ é™¤é€‰ä¸­çš„çŸ¥è¯†åº“", variant="stop")
                        delete_kb_output = gr.Textbox(label="æ“ä½œç»“æœ", lines=2)
                
                gr.Markdown("---")
                gr.Markdown("### ä¸Šä¼ æ–‡æ¡£ä¸æ„å»ºç´¢å¼•")
                
                with gr.Row():
                    with gr.Column():
                        kb_select_for_upload = gr.Dropdown(
                            label="é€‰æ‹©çŸ¥è¯†åº“",
                            choices=get_knowledge_bases(),
                            interactive=True
                        )
                        file_upload = gr.Files(
                            label="ä¸Šä¼  Word æ–‡æ¡£ (.docx)",
                            file_types=[".docx", ".doc"]
                        )
                        upload_btn = gr.Button("ä¸Šä¼ æ–‡æ¡£", variant="primary")
                        upload_output = gr.Textbox(label="ä¸Šä¼ ç»“æœ", lines=3)
                    
                    with gr.Column():
                        build_kb_select = gr.Dropdown(
                            label="é€‰æ‹©çŸ¥è¯†åº“",
                            choices=get_knowledge_bases(),
                            interactive=True
                        )
                        build_btn = gr.Button("æ„å»ºçŸ¥è¯†åº“ç´¢å¼•", variant="primary")
                        build_output = gr.Textbox(label="æ„å»ºç»“æœ", lines=3)
            
            # Tab 2: è¯„æµ‹é›†ç®¡ç†
            with gr.Tab("ğŸ“Š è¯„æµ‹é›†ç®¡ç†"):
                gr.Markdown("""
                ### ä¸Šä¼ è¯„æµ‹é›†
                
                è¯„æµ‹é›†å¿…é¡»æ˜¯ Excel (.xlsx) æ ¼å¼ï¼ŒåŒ…å«ä»¥ä¸‹åˆ—ï¼š
                - `query`: é—®é¢˜
                - `standard_answer`: æ ‡å‡†ç­”æ¡ˆ
                """)
                
                with gr.Row():
                    with gr.Column():
                        eval_file_upload = gr.File(
                            label="ä¸Šä¼ è¯„æµ‹é›† Excel æ–‡ä»¶ (.xlsx)",
                            file_types=[".xlsx"]
                        )
                        upload_eval_btn = gr.Button("ä¸Šä¼ è¯„æµ‹é›†", variant="primary")
                        upload_eval_output = gr.Textbox(label="ä¸Šä¼ ç»“æœ", lines=3)
                    
                    with gr.Column():
                        eval_list = gr.Dropdown(
                            label="å·²ä¸Šä¼ çš„è¯„æµ‹é›†",
                            choices=get_eval_sets(),
                            interactive=True
                        )
                        refresh_eval_btn = gr.Button("åˆ·æ–°è¯„æµ‹é›†åˆ—è¡¨")
            
            # Tab 3: é—®ç­”ä¸è¯„æµ‹
            with gr.Tab("ğŸ’¬ é—®ç­”ä¸è¯„æµ‹"):
                gr.Markdown("### æ™ºèƒ½é—®ç­”ç³»ç»Ÿ")
                
                with gr.Row():
                    with gr.Column(scale=1):
                        qa_kb_select = gr.Dropdown(
                            label="é€‰æ‹©çŸ¥è¯†åº“",
                            choices=get_knowledge_bases(),
                            interactive=True
                        )
                        qa_eval_select = gr.Dropdown(
                            label="é€‰æ‹©è¯„æµ‹é›†ï¼ˆå¯é€‰ï¼‰",
                            choices=get_eval_sets(),
                            interactive=True,
                            value=None
                        )
                        enable_eval_checkbox = gr.Checkbox(
                            label="å¯ç”¨ç­”æ¡ˆè¯„æµ‹ï¼ˆéœ€é€‰æ‹©è¯„æµ‹é›†ï¼‰",
                            value=True
                        )
                        refresh_qa_lists_btn = gr.Button("åˆ·æ–°åˆ—è¡¨")
                    
                    with gr.Column(scale=2):
                        question_input = gr.Textbox(
                            label="è¾“å…¥é—®é¢˜",
                            placeholder="åœ¨è¿™é‡Œè¾“å…¥æ‚¨çš„é—®é¢˜...",
                            lines=3
                        )
                        ask_btn = gr.Button("æé—®", variant="primary", size="lg")
                
                gr.Markdown("---")
                
                with gr.Row():
                    with gr.Column():
                        answer_output = gr.Textbox(
                            label="ğŸ¤– ç”Ÿæˆç­”æ¡ˆ",
                            lines=10
                        )
                    
                    with gr.Column():
                        context_output = gr.Textbox(
                            label="ğŸ“„ æ£€ç´¢ä¸Šä¸‹æ–‡",
                            lines=10
                        )
                
                with gr.Row():
                    with gr.Column(scale=2):
                        eval_output = gr.Textbox(
                            label="ğŸ“Š è¯„æµ‹ç»“æœ",
                            lines=8
                        )
                    
                    with gr.Column(scale=1):
                        time_output = gr.Textbox(
                            label="â±ï¸ è€—æ—¶ç»Ÿè®¡",
                            lines=8
                        )
        
        # äº‹ä»¶ç»‘å®š
        create_kb_btn.click(
            fn=create_knowledge_base,
            inputs=[kb_name_input],
            outputs=[create_kb_output]
        )
        
        delete_kb_btn.click(
            fn=delete_knowledge_base,
            inputs=[kb_list],
            outputs=[delete_kb_output]
        )
        
        refresh_kb_btn.click(
            fn=refresh_kb_list,
            outputs=[kb_list, kb_select_for_upload, build_kb_select, qa_kb_select]
        )
        
        upload_btn.click(
            fn=upload_document,
            inputs=[kb_select_for_upload, file_upload],
            outputs=[upload_output]
        )
        
        build_btn.click(
            fn=build_knowledge_base,
            inputs=[build_kb_select],
            outputs=[build_output]
        )
        
        upload_eval_btn.click(
            fn=upload_eval_set,
            inputs=[eval_file_upload],
            outputs=[upload_eval_output]
        )
        
        refresh_eval_btn.click(
            fn=refresh_eval_list,
            outputs=[eval_list, qa_eval_select]
        )
        
        refresh_qa_lists_btn.click(
            fn=lambda: (gr.update(choices=get_knowledge_bases()), gr.update(choices=get_eval_sets())),
            outputs=[qa_kb_select, qa_eval_select]
        )
        
        ask_btn.click(
            fn=answer_question_sync,
            inputs=[qa_kb_select, qa_eval_select, question_input, enable_eval_checkbox],
            outputs=[answer_output, context_output, eval_output, time_output]
        )
    
    return app


def main():
    """ä¸»å‡½æ•°"""
    print("=" * 80)
    print("æ­£åœ¨å¯åŠ¨ Agentic RAG WebUI...")
    print("=" * 80)
    
    # é¢„åŠ è½½æ¨¡å‹ï¼ˆå¯åŠ¨æ—¶åŠ è½½ï¼Œé¿å…åç»­é‡å¤åŠ è½½ï¼‰
    print("\nğŸ“¦ é¢„åŠ è½½æ¨¡å‹...")
    init_shared_retriever()
    init_kimi_client()
    init_thread_pool(max_workers=4)
    print("\nâœ… æ‰€æœ‰æ¨¡å‹é¢„åŠ è½½å®Œæˆï¼\n")
    
    app = create_webui()
    
    app.launch(
        server_name="0.0.0.0",
        server_port=7860,
        share=False,
        show_error=True
    )


if __name__ == "__main__":
    main()
